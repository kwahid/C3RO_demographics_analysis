{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7f24df",
   "metadata": {},
   "source": [
    "# C3RO demographics analysis base file generator\n",
    "\n",
    "Uses publicly avaliable C3RO image files to generate CSV files which can be used for subsequent linear regression analysis.\n",
    "\n",
    "Utilizes data from here: https://figshare.com/articles/dataset/Large-scale_crowdsourced_radiotherapy_segmentations_across_a_variety_of_cancer_sites/21074182.\n",
    "\n",
    "Author: Kareem A. Wahid.\n",
    "\n",
    "Last edited by Kareem Wahid on August, 23, 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c2cd2",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Helper Functions](#helper)\n",
    "\n",
    "3. [Main code](#maincode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05db4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import os, shutil\n",
    "import SimpleITK as sitk # pip install SimpleITK\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surface_distance import compute_dice_coefficient, compute_surface_distances, compute_robust_hausdorff, compute_surface_dice_at_tolerance, compute_average_surface_distance # installation instructions: https://github.com/deepmind/surface-distance\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3044d",
   "metadata": {},
   "source": [
    "## Helper Functions <a class=\"anchor\" id=\"helper\"></a>\n",
    "\n",
    "Note: Most of this code is (unfortunatley) hard-coded to work with the C3RO data folder/file structures as downloaded from Figshare. If you make alterations to the way the folders are laid out it will probably break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257e5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Kiser et al. https://github.com/kkiser1/Autosegmentation-Spatial-Similarity-Metrics\n",
    "\n",
    "def getEdgeOfMask(mask):\n",
    "    '''\n",
    "    Computes and returns edge of a segmentation mask\n",
    "    '''\n",
    "    # edge has the pixels which are at the edge of the mask\n",
    "    edge = np.zeros_like(mask)\n",
    "    \n",
    "    # mask_pixels has the pixels which are inside the mask of the automated segmentation result\n",
    "    mask_pixels = np.where(mask > 0)\n",
    "\n",
    "    for idx in range(0,mask_pixels[0].size):\n",
    "\n",
    "        x = mask_pixels[0][idx]\n",
    "        y = mask_pixels[1][idx]\n",
    "        z = mask_pixels[2][idx]\n",
    "\n",
    "        # Count # pixels in 3x3 neighborhood that are in the mask\n",
    "        # If sum < 27, then (x, y, z) is on the edge of the mask\n",
    "        if mask[x-1:x+2, y-1:y+2, z-1:z+2].sum() < 27:\n",
    "            edge[x,y,z] = 1\n",
    "            \n",
    "    return edge\n",
    "\n",
    "def AddedPathLength(auto, gt):\n",
    "    '''\n",
    "    Returns the added path length, in pixels\n",
    "    \n",
    "    Steps:\n",
    "    1. Find pixels at the edge of the mask for both auto and gt\n",
    "    2. Count # pixels on the edge of gt that are not in the edge of auto\n",
    "    '''\n",
    "    \n",
    "    # Check if auto and gt have same dimensions. If not, then raise a ValueError\n",
    "    if auto.shape != gt.shape:\n",
    "        raise ValueError('Shape of auto and gt must be identical!')\n",
    "\n",
    "    # edge_auto has the pixels which are at the edge of the automated segmentation result\n",
    "    edge_auto = getEdgeOfMask(auto)\n",
    "    # edge_gt has the pixels which are at the edge of the ground truth segmentation\n",
    "    edge_gt = getEdgeOfMask(gt)\n",
    "    \n",
    "    # Count # pixels on the edge of gt that are on not in the edge of auto\n",
    "    apl = (edge_gt > edge_auto).astype(int).sum()\n",
    "    \n",
    "    return apl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f274159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_main(lst): # main function so you don't waste time \n",
    "    DSC_list = []\n",
    "    HD95_list = []\n",
    "    ASD_list = []\n",
    "    APL_list = []\n",
    "    ordered_list = itertools.combinations(lst,2)\n",
    "    for i in ordered_list:\n",
    "        file_1 = sitk.ReadImage(i[0])\n",
    "        file_2 = sitk.ReadImage(i[1])\n",
    "        \n",
    "        spacing_mm = file_1.GetSpacing() # need spacing to calcualte distances\n",
    "        \n",
    "        mask_1 = sitk.GetArrayFromImage(file_1)\n",
    "        mask_2 = sitk.GetArrayFromImage(file_2)\n",
    "        \n",
    "        DSC = compute_dice_coefficient(mask_1, mask_2)\n",
    "        DSC_list.append(DSC)\n",
    "        \n",
    "        mask_1_bool = mask_1.astype(bool) # need to convert to bool format to work \n",
    "        mask_2_bool = mask_2.astype(bool)\n",
    "        \n",
    "        surface_distances = compute_surface_distances(mask_1_bool, mask_2_bool, spacing_mm) # need this for all calculations\n",
    "        HD95 = compute_robust_hausdorff(surface_distances, 95)\n",
    "        HD95_list.append(HD95)\n",
    "        \n",
    "        ASD_truth = compute_average_surface_distance(surface_distances)[0] #  A tuple with two float values: 1. the average distance (in mm) from the ground truth surface to thepredicted surface, 2. the average distance from the predicted surface to the ground truth surface.\n",
    "        ASD_pred = compute_average_surface_distance(surface_distances)[1]\n",
    "        ASD_mean = (ASD_truth + ASD_pred)/2\n",
    "        ASD_list.append(ASD_mean)\n",
    "        \n",
    "        APL = AddedPathLength(mask_1, mask_2)\n",
    "        APL_list.append(APL)\n",
    "        \n",
    "    return DSC_list, HD95_list, ASD_list, APL_list\n",
    "\n",
    "def pairwise_SDSC(lst, tolerance): # do the same thing for SDSC\n",
    "    SDSC_list = []\n",
    "    ordered_list = itertools.combinations(lst,2)\n",
    "    for i in ordered_list:\n",
    "        file_1 = sitk.ReadImage(i[0])\n",
    "        file_2 = sitk.ReadImage(i[1])\n",
    "        \n",
    "        spacing_mm = file_1.GetSpacing() # need spacing to calcualte distances\n",
    "        \n",
    "        mask_1 = sitk.GetArrayFromImage(file_1)\n",
    "        mask_2 = sitk.GetArrayFromImage(file_2)\n",
    "        \n",
    "        mask_1_bool = mask_1.astype(bool) # need to convert to bool format to work \n",
    "        mask_2_bool = mask_2.astype(bool)\n",
    "        \n",
    "        surface_distances = compute_surface_distances(mask_1_bool, mask_2_bool, spacing_mm) # need this for all calculations\n",
    "        \n",
    "        SDSC = compute_surface_dice_at_tolerance(surface_distances, tolerance)\n",
    "        \n",
    "        SDSC_list.append(SDSC)\n",
    "        \n",
    "    return SDSC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61532e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expert_pairwise_df(site_path, ROI_list):\n",
    "    \n",
    "    expert_path = os.path.join(site_path, \"Segmentations\", \"Expert\")\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns=['ROI', 'DSC_list', 'HD95_list', 'ASD_list', 'APL_list'])\n",
    "    counter = -1  \n",
    "\n",
    "    for ROI in ROI_list:\n",
    "        file_list = []\n",
    "\n",
    "        ID_paths = [os.path.join(expert_path, folder, 'NIFTI') for folder in os.listdir(expert_path) if folder != \"Consensus\"]\n",
    "\n",
    "        for ID_path in ID_paths:\n",
    "\n",
    "            structures = os.listdir(ID_path)\n",
    "            for structure in structures:\n",
    "                structure_path = os.path.join(ID_path, structure)\n",
    "                \n",
    "                #new edit\n",
    "                if ROI in structure.split('.')[0]:\n",
    "                    file_list.append(structure_path)\n",
    "\n",
    "        DSC_list, HD95_list, ASD_list, APL_list = pairwise_main(file_list)\n",
    "\n",
    "        counter +=1\n",
    "        df.loc[counter] = [ROI, DSC_list, HD95_list, ASD_list, APL_list]\n",
    "        \n",
    "    #SDSC\n",
    "    SDSC_master_list = []\n",
    "    for ROI in ROI_list:\n",
    "        file_list = []\n",
    "\n",
    "        ID_paths = [os.path.join(expert_path, folder, 'NIFTI') for folder in os.listdir(expert_path) if folder != \"Consensus\"]\n",
    "\n",
    "        for ID_path in ID_paths:\n",
    "\n",
    "            structures = os.listdir(ID_path)\n",
    "            for structure in structures:\n",
    "                structure_path = os.path.join(ID_path, structure)\n",
    "                #new edit\n",
    "                if ROI in structure.split('.')[0]:\n",
    "                    file_list.append(structure_path)\n",
    "                    \n",
    "        tolerance = np.median(df[(df[\"ROI\"] == ROI)][\"ASD_list\"].values[0]) # get tolerance\n",
    "        SDSC_list = pairwise_SDSC(file_list, tolerance)\n",
    "        SDSC_master_list.append(SDSC_list)\n",
    "    \n",
    "    df['SDSC_list'] = SDSC_master_list\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1c7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nonexpert_vs_expertSTAPLE_df(site_path, ROI_list, expert_pairwise_df):\n",
    "\n",
    "    nonexpert_path = os.path.join(site_path, \"Segmentations\", \"Non-Expert\") # this will be for all the non-experts\n",
    "\n",
    "    expert_staple_path = os.path.join(site_path, \"Segmentations\", \"Expert\", \"Consensus\") # this will be just for STAPLE comparison structure \n",
    "\n",
    "    df = pd.DataFrame(columns=['Record ID', 'ROI', 'DSC', 'HD95', 'APL', 'SDSC'])\n",
    "    counter = -1  \n",
    "\n",
    "    ID_list = [folder for folder in os.listdir(nonexpert_path) if folder != \"Consensus\"]\n",
    "\n",
    "    for ID in ID_list:\n",
    "        \n",
    "        for ROI in ROI_list:\n",
    "\n",
    "            nonexpert_file_path = os.path.join(nonexpert_path, ID, 'NIFTI', ID+'_'+ROI+'.nii.gz')\n",
    "\n",
    "            if os.path.isfile(nonexpert_file_path):\n",
    "\n",
    "                file_1 = sitk.ReadImage(nonexpert_file_path)\n",
    "\n",
    "                expert_file_path = os.path.join(expert_staple_path, ROI+ '_STAPLE.nii.gz')\n",
    "\n",
    "                file_2 = sitk.ReadImage(expert_file_path) # this will for sure exist \n",
    "\n",
    "                mask_1 = sitk.GetArrayFromImage(file_1)\n",
    "                mask_2 = sitk.GetArrayFromImage(file_2)\n",
    "\n",
    "                DSC = compute_dice_coefficient(mask_1, mask_2)  \n",
    "\n",
    "                # adding other metrics\n",
    "\n",
    "                spacing_mm = file_1.GetSpacing() # need spacing to calcualte distances\n",
    "\n",
    "                mask_1_bool = mask_1.astype(bool) # need to convert to bool format to work \n",
    "                mask_2_bool = mask_2.astype(bool)\n",
    "\n",
    "                surface_distances = compute_surface_distances(mask_1_bool, mask_2_bool, spacing_mm) # need this for all calculations\n",
    "                HD95 = compute_robust_hausdorff(surface_distances, 95)\n",
    "\n",
    "                ASD_truth = compute_average_surface_distance(surface_distances)[0] #  A tuple with two float values: 1. the average distance (in mm) from the ground truth surface to thepredicted surface, 2. the average distance from the predicted surface to the ground truth surface.\n",
    "                ASD_pred = compute_average_surface_distance(surface_distances)[1]\n",
    "                ASD = (ASD_truth + ASD_pred)/2\n",
    "\n",
    "                APL = AddedPathLength(mask_1, mask_2)\n",
    "\n",
    "                tolerance = np.median(expert_pairwise_df[(expert_pairwise_df[\"ROI\"] == ROI)][\"ASD_list\"].values[0]) # get tolerance\n",
    "                SDSC = compute_surface_dice_at_tolerance(surface_distances, tolerance)\n",
    "\n",
    "                counter +=1\n",
    "                df.loc[counter] = [ID, ROI, DSC, HD95, APL, SDSC]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62975b4e",
   "metadata": {},
   "source": [
    "## Main code <a class=\"anchor\" id=\"maincode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818dc8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:60: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcoma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:60: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H&N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:60: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GYN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:60: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GI\n",
      "Wall time: 1h 10min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:60: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_path = \"Z:\\\\Kareem\\\\C3RO\\\\data_descriptor\\\\Organized_files_v4\" # path to the data (top-level folder) from Figshare here\n",
    "\n",
    "# disease site name mapped to list of corresponding ROIs and sheet name of excel file \n",
    "site_lists = [\n",
    "    ['Breast', ['BrachialPlex_L','CTV_Ax','CTV_Chestwall','CTV_IMN','CTV_Sclav_LN','Heart', 'A_LAD'], 0],\n",
    "    ['Sarcoma', ['GTV', 'CTV', 'Genitals'], 1],\n",
    "    ['H&N', ['GTVp', 'GTVn', 'CTV1', 'CTV2', 'Brainstem', 'Glnd_Submand_L', 'Glnd_Submand_R', 'Larynx', 'Musc_Constrict', 'Parotid_L', 'Parotid_R'], 2],\n",
    "    ['GYN', ['GTVn', 'CTVn_4500', 'CTVp_4500', 'Bowel_Small'], 3],\n",
    "    ['GI', ['CTV_4500', 'CTV_5400', 'Bag_Bowel'], 4]\n",
    "                ] \n",
    "\n",
    "binarized_metrics = [\n",
    "    \"DSC_binary\",\n",
    "    \"SDSC_binary\"\n",
    "              ]\n",
    "\n",
    "for site in site_lists:\n",
    "    site_name = site[0]\n",
    "    print(site_name) # debug\n",
    "    ROI_list = site[1]\n",
    "    sheet_number = site[2]\n",
    "    \n",
    "    site_path = os.path.join(data_path, site_name) # path to disease site folder\n",
    "    \n",
    "    df_expert_pairwise = generate_expert_pairwise_df(site_path, ROI_list) # calculate expert pairwise values for benchmarking\n",
    "    \n",
    "    df_nonexpert_vs_STAPLE = generate_nonexpert_vs_expertSTAPLE_df(site_path, ROI_list, df_expert_pairwise) # calculate individual non-experts vs expert consensus\n",
    "    df_nonexpert_vs_STAPLE['Record ID'] = df_nonexpert_vs_STAPLE['Record ID'].astype('int64') # object to int\n",
    "    \n",
    "    ### integrate the cutoff values and categories into a 2 new columns\n",
    "    for metric in binarized_metrics:\n",
    "        metric_name = metric.split('_')[0]\n",
    "        \n",
    "        # for easier access to column names\n",
    "        metric_median = metric_name+'_expert_IOV'\n",
    "        metric_list = metric_name+'_list'\n",
    "        \n",
    "        df_expert_pairwise[metric_median] = df_expert_pairwise[metric_list].apply(np.median)\n",
    "        \n",
    "        # Merge the dataframes on the 'ROI' column\n",
    "        df_nonexpert_vs_STAPLE = pd.merge(df_nonexpert_vs_STAPLE, df_expert_pairwise[['ROI', metric_median]], on='ROI', how='left')\n",
    "        # Create a new column that's 1 if 'DSC' > 'IOV', and 0 otherwise\n",
    "        df_nonexpert_vs_STAPLE[metric] = (df_nonexpert_vs_STAPLE[metric_name] > df_nonexpert_vs_STAPLE[metric_median]).astype(int)\n",
    "        \n",
    "    ### integrate the demographic variable data \n",
    "\n",
    "    # get excel file\n",
    "    excel_file_path = os.path.join(data_path, \"C3RO_RedCap_est7.30.22.xlsx\") # path to excel file with observer demographic data\n",
    "    excel_df = pd.read_excel(excel_file_path, sheet_name=sheet_number) # sheet names as defined above \n",
    "    excel_df = excel_df[excel_df[\"Category\"] == \"Non-expert\"] # only pick non-experts\n",
    "    \n",
    "    # merge the excel into main dataframe\n",
    "    df_final = pd.merge(df_nonexpert_vs_STAPLE, excel_df, on = \"Record ID\", how = 'left')\n",
    "\n",
    "    # create total years of practice variable\n",
    "    df_final['What year did you start practicing (graduate residency)?'] = pd.to_numeric(df_final['What year did you start practicing (graduate residency)?'], errors='coerce') # new, need to make sure it gives same value\n",
    "    df_final['Total years of practice'] = 2022 - df_final['What year did you start practicing (graduate residency)?']\n",
    "\n",
    "    # clean column names for ease of use later\n",
    "    df_final.columns = df_final.columns.str.replace(' ', '_').str.replace('\\W', '') \n",
    "    df_final = df_final.rename(columns={\n",
    "        'Which_best_describes_your_primary_practice_': 'Practice_type', \n",
    "        'How_many_radiation_oncologist_colleagues_do_you_work_with_at_your_primary_site_excluding_you_': 'Colleague_num', \n",
    "        'WHITE_Which_categories_describe_you___Select_all_that_apply___choiceWhite': 'Race_white', \n",
    "        'Do_you_have_an_academic_affiliation': 'Academic_affiliation',\n",
    "        \"On_most_days_you_are_in_clinic_is_there_another_radiation_oncologist_on_site_with_you_\": 'Colleague_presence'\n",
    "    })\n",
    "    df_final.columns = df_final.columns.str.replace(\"Which_disease_sites_do_you_treat___Select_all_that_apply_choice\", \"Treat_site_\")\n",
    "    \n",
    "    ### write to CSV file\n",
    "    csv_file_path = 'csv_files\\\\' + site_name + '.csv'\n",
    "    df_final.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0801ac-100c-4770-8007-1a7cd5327792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_ID</th>\n",
       "      <th>ROI</th>\n",
       "      <th>DSC</th>\n",
       "      <th>HD95</th>\n",
       "      <th>APL</th>\n",
       "      <th>SDSC</th>\n",
       "      <th>DSC_expert_IOV</th>\n",
       "      <th>DSC_binary</th>\n",
       "      <th>SDSC_expert_IOV</th>\n",
       "      <th>SDSC_binary</th>\n",
       "      <th>...</th>\n",
       "      <th>Treat_site_Genitourinary</th>\n",
       "      <th>Treat_site_Gynecologic</th>\n",
       "      <th>Treat_site_Head__Neck</th>\n",
       "      <th>Treat_site_Lung_Thoracic</th>\n",
       "      <th>Treat_site_Lymphoma_Leukemia</th>\n",
       "      <th>Treat_site_Metastatic</th>\n",
       "      <th>Treat_site_Pediatric</th>\n",
       "      <th>Treat_site_Sarcoma</th>\n",
       "      <th>Treat_site_Skin_Cutaneous</th>\n",
       "      <th>Total_years_of_practice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1051</td>\n",
       "      <td>CTV_4500</td>\n",
       "      <td>0.620026</td>\n",
       "      <td>31.249985</td>\n",
       "      <td>95424</td>\n",
       "      <td>0.571932</td>\n",
       "      <td>0.759432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704576</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051</td>\n",
       "      <td>CTV_5400</td>\n",
       "      <td>0.620685</td>\n",
       "      <td>20.255470</td>\n",
       "      <td>13187</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.621064</td>\n",
       "      <td>0</td>\n",
       "      <td>0.782480</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051</td>\n",
       "      <td>Bag_Bowel</td>\n",
       "      <td>0.729188</td>\n",
       "      <td>16.248541</td>\n",
       "      <td>57411</td>\n",
       "      <td>0.707708</td>\n",
       "      <td>0.635979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646844</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073</td>\n",
       "      <td>CTV_4500</td>\n",
       "      <td>0.785915</td>\n",
       "      <td>23.457825</td>\n",
       "      <td>84038</td>\n",
       "      <td>0.752650</td>\n",
       "      <td>0.759432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704576</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073</td>\n",
       "      <td>CTV_5400</td>\n",
       "      <td>0.540104</td>\n",
       "      <td>22.821624</td>\n",
       "      <td>14670</td>\n",
       "      <td>0.911699</td>\n",
       "      <td>0.621064</td>\n",
       "      <td>0</td>\n",
       "      <td>0.782480</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Checked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_ID        ROI       DSC       HD95    APL      SDSC  DSC_expert_IOV  \\\n",
       "0       1051   CTV_4500  0.620026  31.249985  95424  0.571932        0.759432   \n",
       "1       1051   CTV_5400  0.620685  20.255470  13187  0.940841        0.621064   \n",
       "2       1051  Bag_Bowel  0.729188  16.248541  57411  0.707708        0.635979   \n",
       "3       1073   CTV_4500  0.785915  23.457825  84038  0.752650        0.759432   \n",
       "4       1073   CTV_5400  0.540104  22.821624  14670  0.911699        0.621064   \n",
       "\n",
       "   DSC_binary  SDSC_expert_IOV  SDSC_binary  ... Treat_site_Genitourinary  \\\n",
       "0           0         0.704576            0  ...                Unchecked   \n",
       "1           0         0.782480            1  ...                Unchecked   \n",
       "2           1         0.646844            1  ...                Unchecked   \n",
       "3           1         0.704576            1  ...                  Checked   \n",
       "4           0         0.782480            1  ...                  Checked   \n",
       "\n",
       "  Treat_site_Gynecologic Treat_site_Head__Neck Treat_site_Lung_Thoracic  \\\n",
       "0              Unchecked               Checked                Unchecked   \n",
       "1              Unchecked               Checked                Unchecked   \n",
       "2              Unchecked               Checked                Unchecked   \n",
       "3                Checked               Checked                  Checked   \n",
       "4                Checked               Checked                  Checked   \n",
       "\n",
       "  Treat_site_Lymphoma_Leukemia Treat_site_Metastatic Treat_site_Pediatric  \\\n",
       "0                    Unchecked             Unchecked            Unchecked   \n",
       "1                    Unchecked             Unchecked            Unchecked   \n",
       "2                    Unchecked             Unchecked            Unchecked   \n",
       "3                      Checked               Checked            Unchecked   \n",
       "4                      Checked               Checked            Unchecked   \n",
       "\n",
       "  Treat_site_Sarcoma Treat_site_Skin_Cutaneous  Total_years_of_practice  \n",
       "0          Unchecked                 Unchecked                      7.0  \n",
       "1          Unchecked                 Unchecked                      7.0  \n",
       "2          Unchecked                 Unchecked                      7.0  \n",
       "3          Unchecked                 Unchecked                      4.0  \n",
       "4          Unchecked                 Unchecked                      4.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head() # show a sample of what the dataframe looks like, if running in order this will be GI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450e45d-565a-46c9-876b-de1550992489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
